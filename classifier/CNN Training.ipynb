{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing import image as img_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define a dictionary which allows us to allocate\n",
    "labels that we want to each folder that we create.\n",
    "It contains mapping from folder path to label.\n",
    "\n",
    "This is included for the continuous labels that we \n",
    "plan to allocate to certain samples. \n",
    "\n",
    "This represents one 'Scenario'\n",
    "\n",
    "To create a new scenario, just add/remove/change \n",
    "the mappings of filepaths and labels.\n",
    "'''\n",
    "\n",
    "label_mapping = {\n",
    "    'data/Archive/BadData1': 0.0,\n",
    "    'data/Archive/BadData2': 0.0,\n",
    "    'data/Archive/GoodData': 1.0,\n",
    "    'data/Archive/TrueData': 1.0,\n",
    "    'data/Archive1/TrueGoodData': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We now define a custom DataGenerator class to incorporate \n",
    "parallel loading of data on the CPU while GPU trains a batch.\n",
    "\n",
    "This will prevent overloading the RAM of the system. \n",
    "This scheme will act similar to the Datagenerator+Dataloader \n",
    "interface of PyTorch.\n",
    "'''\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    '''\n",
    "    Data generator class\n",
    "    '''\n",
    "    def __init__(self, label_mapping, batch_size=128, shuffle=True,\n",
    "                 image_size=(256,256)):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_df = self.get_data_df(label_mapping)\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def get_data_df(self, label_mapping):\n",
    "        '''\n",
    "        Produces a dataframe of filepath of each image and\n",
    "        its label. \n",
    "        '''\n",
    "        \n",
    "        data_dicts = []\n",
    "        \n",
    "        for folder_path in label_mapping:\n",
    "            \n",
    "            label = label_mapping[folder_path]\n",
    "            \n",
    "            for image_name in os.list_dir(folder_path):\n",
    "                record = {}\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                record['ImagePath'] = image_path\n",
    "                record['Label'] = label\n",
    "                data_dicts.append(record)\n",
    "        \n",
    "        return pd.DataFrame(data_dicts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Get one batch of data \n",
    "        '''\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        X, y = self.__data_generation(indexes)\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def on_epoch_end(self):       \n",
    "        'Updates indexes after each epoch'\n",
    "        \n",
    "        self.indexes = np.arange(len(self.data_df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, indexes, image_preprocess=None):\n",
    "        '''\n",
    "        Depending on the indexes, reads images and preprocesses \n",
    "        them by the callable image_preprocess and processes the labels\n",
    "        '''\n",
    "        batch_df = self.df.iloc[indexes]\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        \n",
    "        for i in range(len(batch_df)):\n",
    "            \n",
    "            image_path = batch_df['ImagePath'].iloc[i]\n",
    "            label = batch_df['Label'].iloc[i]\n",
    "            \n",
    "            image = img_proc.load_img(image_path, grayscale=True,\n",
    "                                      target_size=self.image_size)\n",
    "            img = img_proc.img_to_array(image)\n",
    "            image_list.append(img)\n",
    "            \n",
    "            label_ = [1-label, label]\n",
    "            label_list.append(label)\n",
    "        \n",
    "        return np.array(image_list), np.array(label_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
